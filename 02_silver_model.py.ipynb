{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ede37bb-b1d7-4397-bb1b-b814c999173d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "CATALOG = \"music_demo\"\n",
    "BRONZE  = \"bronze\"\n",
    "SILVER  = \"silver\"\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {SILVER}\")\n",
    "spark.sql(f\"USE {SILVER}\")\n",
    "\n",
    "def to_int(col):\n",
    "    # empty -> null, non-numeric -> null, else cast\n",
    "    return F.when(F.trim(F.col(col)) == \"\", None) \\\n",
    "            .otherwise(F.col(col)).cast(\"int\")\n",
    "\n",
    "def to_bigint(col):\n",
    "    return F.when(F.trim(F.col(col)) == \"\", None) \\\n",
    "            .otherwise(F.col(col)).cast(\"bigint\")\n",
    "\n",
    "def to_date(col, fmt=\"yyyy-MM-dd\"):\n",
    "    # empty -> null, else to_date\n",
    "    return F.to_date(F.when(F.trim(F.col(col)) == \"\", None).otherwise(F.col(col)), fmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21ce5c96-8da4-4514-8982-fceb2a5088ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_art = spark.table(f\"{CATALOG}.{BRONZE}.artists\")  # all strings\n",
    "\n",
    "dim_artist = (bronze_art\n",
    "    .select(\n",
    "        F.col(\"artist_id\"),\n",
    "        F.col(\"artist_name\"),\n",
    "        F.col(\"genre\"),\n",
    "        F.col(\"country_of_origin\"),\n",
    "        to_int(\"debut_year\").alias(\"debut_year\"),\n",
    "    )\n",
    "    .dropDuplicates([\"artist_id\"])\n",
    ")\n",
    "\n",
    "dim_artist.write.mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{CATALOG}.{SILVER}.dim_artist\")\n",
    "display(spark.sql(f\"SELECT * FROM {CATALOG}.{SILVER}.dim_artist LIMIT 5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "970096b1-a2a2-4034-b59b-ba124fefde56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_tr = spark.table(f\"{CATALOG}.{BRONZE}.tracks\")\n",
    "\n",
    "dim_track = (bronze_tr\n",
    "    .select(\n",
    "        F.col(\"track_id\"),\n",
    "        F.col(\"artist_id\"),\n",
    "        F.col(\"track_title\"),\n",
    "        to_date(\"release_date\").alias(\"release_date\"),   # cast safely\n",
    "        F.col(\"primary_genre\"),\n",
    "    )\n",
    "    .dropDuplicates([\"track_id\"])\n",
    ")\n",
    "\n",
    "dim_track.write.mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{CATALOG}.{SILVER}.dim_track\")\n",
    "display(spark.sql(f\"SELECT * FROM {CATALOG}.{SILVER}.dim_track LIMIT 5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a56fac0-968b-42c8-b30a-2c918cd2a851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_m = spark.table(f\"{CATALOG}.{BRONZE}.daily_metrics\")\n",
    "\n",
    "fact_metrics = (bronze_m\n",
    "    .select(\n",
    "        to_date(\"date\").alias(\"date\"),\n",
    "        F.col(\"platform\"),\n",
    "        F.col(\"region\"),\n",
    "        F.col(\"artist_id\"),\n",
    "        F.col(\"track_id\"),\n",
    "        to_bigint(\"streams\").alias(\"streams\"),\n",
    "        to_bigint(\"views\").alias(\"views\"),\n",
    "        to_bigint(\"likes\").alias(\"likes\"),\n",
    "        to_bigint(\"comments\").alias(\"comments\"),\n",
    "        to_bigint(\"shares\").alias(\"shares\"),\n",
    "        to_bigint(\"followers_gained\").alias(\"followers_gained\"),\n",
    "        to_int(\"rank_estimate\").alias(\"rank_estimate\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fact_metrics.write.mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{CATALOG}.{SILVER}.fact_metrics\")\n",
    "display(spark.sql(f\"SELECT COUNT(*) rows FROM {CATALOG}.{SILVER}.fact_metrics\"))\n",
    "display(spark.sql(f\"\"\"\n",
    "SELECT date, platform, region, streams, views\n",
    "FROM {CATALOG}.{SILVER}.fact_metrics\n",
    "ORDER BY date DESC\n",
    "LIMIT 10\n",
    "\"\"\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_model.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
